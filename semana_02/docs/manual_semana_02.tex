\documentclass[12pt, a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{geometry}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{tcolorbox}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}

\geometry{top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm}

% Configuración de Estilo de Código (VS Code Theme)
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{deepblue},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{deepred},
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2,
    literate={á}{{\'a}}1 {é}{{\'e}}1 {í}{{\'i}}1 {ó}{{\'o}}1 {ú}{{\'u}}1 {ñ}{{\~n}}1
}
\lstset{style=mystyle}

\title{\textbf{Manual de Ingeniería II: Computación Numérica y Lógica}\\ De Python Puro a la Vectorización}
\author{Semana 02 - Curso de IA Agroindustrial}
\date{\today}

\begin{document}

\maketitle
\tableofcontents
\newpage

\section{Introducción: La Necesidad de Velocidad}
En la Semana 1 dominamos el sistema operativo. En la Semana 2, entramos al núcleo del procesamiento de datos.

En IA, no procesamos 10 datos; procesamos millones (imágenes satelitales, series temporales de sensores). Python, por sí solo, es un lenguaje interpretado y lento para bucles masivos. Aquí es donde entra la **Computación Vectorial**.

\section{Parte 1: Lógica y Estructuras de Datos (Python Puro)}
Antes de correr, debemos caminar. El script \texttt{main.py} aborda la limpieza de datos secuencial.

\subsection{El Costo de las Listas en Python}
Una lista en Python (\texttt{list}) no es un array contiguo de memoria como en C. Es un array de \textbf{punteros} a objetos.
$$ \text{Lista} = [\text{ptr} \to \text{Obj(24.5)}, \quad \text{ptr} \to \text{Obj(None)}, \quad \dots] $$
Cada vez que iteramos sobre una lista, el procesador debe:
\begin{enumerate}
    \item Leer el puntero.
    \item Ir a la dirección de memoria del objeto.
    \item Verificar el tipo de dato (Dynamic Typing check).
    \item Obtener el valor.
\end{enumerate}
Esto genera lo que llamamos \textit{Overhead} computacional.

\subsection{Algoritmo de Limpieza (Data Cleaning)}
En el taller, implementamos un filtro de "paso bajo" lógico:
\begin{lstlisting}[language=Python]
# Complejidad Temporal: O(N) - Lineal
for lectura in sensores:
    if lectura is None: continue      # Manejo de Nulls
    if 0 <= lectura <= 50:            # Validacion de Rango Fisico
        datos_limpios.append(lectura) # Mutacion de lista
\end{lstlisting}

\textbf{Concepto Clave:} La complejidad es $O(N)$, donde $N$ es el número de sensores. Si $N=1,000,000$, el bucle se ejecutará un millón de veces secuencialmente.

\section{Parte 2: Vectorización con NumPy}
NumPy (Numerical Python) resuelve el problema de la velocidad cambiando la estrategia:
\begin{enumerate}
    \item \textbf{Memoria Contigua:} Los datos están uno al lado del otro en RAM (Localidad de Caché).
    \item \textbf{Tipado Estático:} Todos los elementos son del mismo tipo (ej. \texttt{float64}).
    \item \textbf{SIMD (Single Instruction, Multiple Data):} El procesador aplica la misma operación a múltiples datos simultáneamente.
\end{enumerate}

\subsection{Broadcasting y Operaciones Element-wise}
En el script \texttt{simulacion.py}, no usamos bucles \texttt{for}. Usamos operaciones vectoriales.

\textbf{Ejemplo Matemático:}
Si queremos normalizar una matriz $A$ restando el mínimo $\mu$:
$$ A_{norm} = A - \mu $$
En Python puro, esto requiere iterar. En NumPy, gracias al \textit{Broadcasting}, se resta $\mu$ a cada elemento de la matriz en paralelo (a nivel de CPU).

\subsection{Filtrado Booleano (Masking)}
Una de las herramientas más potentes en IA es la máscara booleana.
\begin{lstlisting}[language=Python]
# Genera una matriz de True/False
mapa_alertas = mapa_termico > 40.0 
\end{lstlisting}
Esto evalúa $1,000,000$ de píxeles casi instantáneamente. Matemáticamente, es una función indicador:
$$ I(x) = \begin{cases} 1 & \text{si } x > 40 \\ 0 & \text{si } x \leq 40 \end{cases} $$

\section{Análisis de los Retos Propuestos}

\subsection{Reto 1: Normalización Min-Max (Feature Scaling)}
Las Redes Neuronales aprenden mejor cuando los datos están entre 0 y 1. La fórmula formal que deben aplicar es:
$$ X_{norm} = \frac{X - X_{min}}{X_{max} - X_{min}} $$
En NumPy, esto se escribe en una sola línea gracias al broadcasting, sin bucles.

\subsection{Reto 2: Búsqueda Espacial (Argmax)}
Encontrar el máximo es fácil ($\max(A)$). Encontrar \textbf{dónde} está es más complejo.
\begin{itemize}
    \item \texttt{np.argmax}: Devuelve el índice como si la matriz fuera una lista plana de 1 dimensión.
    \item \texttt{np.unravel\_index}: Convierte ese índice plano de vuelta a coordenadas $(x, y)$.
\end{itemize}

\subsection{Reto 3: Imputación Condicional (np.where)}
En ingeniería de datos, "Imputar" significa reemplazar un dato faltante o erróneo.
\begin{lstlisting}[language=Python]
# np.where(condicion, valor_si_true, valor_si_false)
mapa_corregido = np.where(mapa < 21, promedio, mapa)
\end{lstlisting}
Esto es equivalente a escribir un millón de \texttt{if-else}, pero ejecutado en C optimizado.

\section{Conclusión: El Perfil del Ingeniero de IA}
\begin{itemize}
    \item Un programador normal escribe bucles.
    \item Un ingeniero de datos piensa en \textbf{Vectores y Matrices}.
\end{itemize}
Al eliminar los bucles explícitos de su código, no solo lo hace más rápido, sino más legible y cercano a la notación matemática de los algoritmos de aprendizaje automático.

\end{document}
